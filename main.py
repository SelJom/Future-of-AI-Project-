import streamlit as st
import json
import os
from dotenv import load_dotenv

# --- IMPORTS DE VOTRE APPLICATION ---
# Assurez-vous que ces fichiers existent bien dans votre dossier app/
from app.vision import analyze_prescription, process_file_to_images

# Importez ici votre graph existant. 
# Si votre logique de chat est dans app/graph.py, d√©commentez la ligne suivante :
# from app.graph import graph 

# --- CONFIGURATION ---
load_dotenv()
st.set_page_config(page_title="Future of AI - Sant√©", page_icon="üè•", layout="wide")

# --- CSS PERSONNALIS√â (Optionnel) ---
st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] { gap: 24px; }
    .stTabs [data-baseweb="tab"] { height: 50px; white-space: pre-wrap; background-color: #f0f2f6; border-radius: 4px 4px 0 0; gap: 1px; padding-top: 10px; padding-bottom: 10px; }
    .stTabs [aria-selected="true"] { background-color: #ffffff; border-bottom: 2px solid #ff4b4b; }
</style>
""", unsafe_allow_html=True)

# --- TIRE & HEADER ---
st.title("üè• Assistant M√©dical & Pharmacien IA")
st.markdown("---")

# --- STRUCTURE EN ONGLETS ---
tab_chat, tab_scan = st.tabs(["üí¨ Assistant Chat", "üíä Scanner Ordonnance"])

# =========================================================
# ONGLET 1 : VOTRE CHATBOT (LangGraph / RAG)
# =========================================================
with tab_chat:
    st.subheader("Discussion avec l'Assistant")
    
    # -----------------------------------------------------
    # ICI : COLLEZ VOTRE LOGIQUE DE CHAT EXISTANTE
    # -----------------------------------------------------
    
    # Exemple de structure standard Streamlit (√† adapter selon votre code actuel)
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Afficher l'historique
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Zone de saisie
    if prompt := st.chat_input("Posez une question sur vos documents..."):
        # 1. Afficher le message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 2. Appeler votre Graph / LLM
        with st.chat_message("assistant"):
            with st.spinner("R√©flexion en cours..."):
                # --- REMPLACEZ CECI PAR L'APPEL A VOTRE GRAPH ---
                # response = graph.invoke({"question": prompt})
                # final_answer = response['answer'] 
                
                # Pour le test (si le graph n'est pas encore reli√©) :
                final_answer = "Ceci est une r√©ponse simul√©e. Reliez votre 'app.graph' ici."
                # ------------------------------------------------
                
                st.markdown(final_answer)
        
        st.session_state.messages.append({"role": "assistant", "content": final_answer})


# =========================================================
# ONGLET 2 : SCANNER D'ORDONNANCE (Vision Llama 3.2)
# =========================================================
with tab_scan:
    st.subheader("Num√©risation et Analyse d'Ordonnance")
    
    col_upload, col_info = st.columns([2, 1])
    
    with col_info:
        st.info("‚ÑπÔ∏è **Mod√®le actif :** Llama 3.2 Vision\n\nCe module utilise votre carte graphique locale pour lire les ordonnances (PDF ou Photos) et extraire les m√©dicaments au format JSON.")

    with col_upload:
        uploaded_file = st.file_uploader("D√©posez votre ordonnance ou photo de m√©dicament", type=['png', 'jpg', 'jpeg', 'pdf'])

    if uploaded_file:
        # Traitement du fichier via le module vision
        images_data, error = process_file_to_images(uploaded_file)
        
        if error:
            st.error(error)
        elif images_data:
            # Bouton d'action
            if st.button("üöÄ Lancer l'analyse IA", type="primary"):
                
                # Barre de progression globale
                progress_bar = st.progress(0)
                total_images = len(images_data)
                
                for index, (label, img_pil, img_bytes) in enumerate(images_data):
                    st.markdown("---")
                    c1, c2 = st.columns([1, 1])
                    
                    # Colonne gauche : Image
                    with c1:
                        st.image(img_pil, caption=f"Source : {label}", use_container_width=True)
                    
                    # Colonne droite : R√©sultat
                    with c2:
                        st.markdown(f"**Analyse de {label}...**")
                        with st.spinner("Lecture des caract√®res manuscrits..."):
                            raw_result = analyze_prescription(img_bytes)
                            
                            # Nettoyage et affichage du JSON
                            try:
                                # Chercher les accolades JSON dans la r√©ponse du LLM
                                start = raw_result.find('{')
                                end = raw_result.rfind('}') + 1
                                if start != -1 and end != -1:
                                    json_obj = json.loads(raw_result[start:end])
                                    st.success("‚úÖ Lecture termin√©e")
                                    st.json(json_obj)
                                else:
                                    st.warning("‚ö†Ô∏è Format non structur√© d√©tect√©")
                                    st.text_area("R√©sultat brut", raw_result, height=200)
                            except json.JSONDecodeError:
                                st.warning("‚ö†Ô∏è Erreur de parsing JSON")
                                st.text_area("R√©sultat brut", raw_result, height=200)
                    
                    # Mise √† jour de la barre de progression
                    progress_bar.progress((index + 1) / total_images)